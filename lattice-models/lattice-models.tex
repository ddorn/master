\input{../preambule.tex}


\title{Lattice Models}
\author{Diego Dorn \\ Lectures notes from Frank Gabriel}
\date{Automn 2021}

\newcommand{\Isom}{\mathrm{Isom}}
\newcommand{\Acts}{\curvearrowright}
\renewcommand{\P}[1]{\mathbb{P}\hspace{-0.3ex}\left(#1\right)}
\newcommand{\Pcond}[2]{\mathbb{P}\hspace{-0.3ex}\left(#1 \middle| #2 \right)}
\newcommand{\E}[1]{\mathbb{E}\left[#1\right]}
\newcommand{\Fourrier}{\mathcal F}
\newcommand{\IE}{\mathbb{E}}

\begin{document}
    \maketitle

    % \tableofcontents
    \section{Simple random walks}

    \begin{theorem}
        Let $S_n$ be a simple random walk on $\Z^d$.
        \begin{itemize}
            \item If $d = 1, 2$ then $\P{\exists n, S_n = 0} = 1$.
            \item If $d \geq 3$, $\P{\exists n, S_n = 0} < 1$.
        \end{itemize}
    \end{theorem}

    The proof is in five parts.

    \begin{claim}
        If the theorem holds for $d = 1, 2, 3$ then it holds for general $d$.
    \end{claim}
    \begin{proof}
        Let $d > 3$, $S_n$ a SRW in $\Z^d$.
        We consider \[
            \func{\pi}{\Z^d}{\Z^3}
            {(x_1, \dots, x_n)}{(x_1, x_2, x_3)}
        \]
        We consider $\pi(S_n) = \tilde{S}_n \in \Z^3$:
        \begin{itemize}
            \item $\tilde{S}_0 = (0, 0, 0)$.
            \item There are some times where $\tilde{S}_n = \tilde{S}_{n+1}$.
                each time it is the $k$-th coordinate of $S_n$ that changes, with $k > 3$.
            \item Each time $\tilde{S}_n \neq \tilde{S}_{n+1}$, 
                the move was to take uniformly a neighbour of $\tilde{S}_n$.
            \item If we look at on only when $\tilde{S}_n$ moves,
                we obtain a simple random walk $\hat{S}_n$.
        \end{itemize}
        But $\P{\exists n, \hat S_n = (0, 0, 0)} < 1$ by hypothesis, 
        and since $\mathrm{range}(\tilde S_n) = \mathrm{range}(\hat S_n)$,
        we obtain
        $\P{\exists n, \tilde S_n = (0, 0, 0)} < 1$.
        and so must be the probability for $S_n$.
    \end{proof}

    \begin{claim}
        Let $N_d$ be the number of vists to $0$ after time $n = 0$.
        Then $\E{N_d} = \infty$ if and only if
         $\pi_d := \P{\exists n > 0, S_n = 0} = 1$.
    \end{claim}

    \begin{proof}
        \begin{align*}
            \E{N_d} &=
            \sum_{k=1}^n k \P{N_d = k}
            \\&=
            \sum_{k > 0} \sum_{j > 0} \mathbb{1}_{j \leq k}
                \P{N_d = k}
            \\&=
            \sum_{j > 0} \sum_{k > 0} \mathbb{1}_{j \leq k}
                \P{N_d = k}
            \\&=
            \sum_{j > 0} \sum_{k > j} \P{N_d = k}
            \\&=
            \sum_{j > 0} \P{N_d \geq j}
        \end{align*}

        We compute $\P{N_d \geq j} = \bigparenthesis{
            \P{\exists n, S_n = 0}
        }^j = \pi_d^j$.
        So \begin{align*}
            \E{N_d} = \sum_{j = 1}^\infty \pi_d^j = \frac{\pi_d}{1 - \pi_d}
            = \begin{cases}
                \infty & \tif \pi_d = 1 \\
                c < \infty & \tif \pi_d < 1
            \end{cases}
        \end{align*}
    \end{proof}

    \begin{claim}
        Let $P_n(x) = \P{S_n = x}$.
        We have
        \[
            P_{n+1} = P_n * P_1 = P_1^{*(n+1)}
        \]
        where $(f * g)(x) = \sum_{z \in \Z^d} f(z)g(x - z)$.
    \end{claim}

    \begin{proof}
        Let $Q_n(x, y) = \P{S_n = x | S_0 = y}$, so that $P_n(x) = Q_n(0, x)$.
        The semi random walk satifies the invariance by translation:
        \[
            \P{S_1 = x \pm 1 | S_0 = x}
            = 
            \P{S_1 = \pm 1 | S_0 = 0}
        \]
        And more generally, for all $z \in \Z^d$, we have
        \[
            \Pcond{S_n = y}{S_0 = x}
            = 
            \Pcond{S_n = y + z}{S_0 = x + z}.
        \]
        So, $P_n(x) := Q_n(0, x)$ and $Q_n(x, y) = P(y - x)$.
        \begin{align*}
            Q_{n + 1}(x, y) 
            &= 
            \Pcond{S_{n+1} = y}{S_0 = y}
            \\&=
            P_x(S_{n+1} = y)
            \\ &= 
            \sum_z P_x(S_{n+1} = y \andd S_1 = z)
            \\&=
            \sum_z \underbrace{
                P_x(S_{n+1} = y | S_1 = z) 
            }_{Q_n(z, y)}
            \underbrace{
                \Pcond{S_1 = z}{S_0 = x}
            }_{Q_1(x, y)}
        \end{align*}

        So \[
            Q_{n+1}(x, y) = \sum_{z \in \Z^d}
                Q_1(x, z) Q_n(z, y)
        \]  % Seems obvious... ?
        Which is a matrix multiplication, 
        so $Q_{n+1} = Q_1 \cdot Q_n = Q_1^{n+1}$.

        \[
            P_{n+1}(x) = Q_{n+1}(0, x) = 
            \sum_z Q_n(0, z) Q_1(z, x)
            = \sum_z P_n(z) P_1(x - z).
        \]
        That is, 
        \[
            P_{n+1} = P_n * P_1 = P_1^{*(n+1)}
        \]
        where $(f * g)(x) = \sum_{z \in \Z^d} f(z)g(x - z)$.
    \end{proof}

    \begin{claim}
        ...
    \end{claim}

    \begin{proof}
        We compute $P_n(x)$ via a Fourrier transform.
        If $f: \Z^d \to \R$ is a function of finite support,
        its Fourrier transform is
        \[
            \func{\Fourrier f}{\R}{\C}
            {\Fourrier f(x)} {
                \sum_{k \in \Z^d} f(k) e^{ikx}
            }
        \]
        which satisfies \begin{itemize}
            \item $\Fourrier(f * g)(x) = \Fourrier(f)(x) \Fourrier(g)(x)$.
            \item \[
                f(k) = \frac{1}{2\pi} \int_{-\pi}^\pi \Fourrier f(x) e^{-ikx} \, dx
            \]
        \end{itemize}

        Now, \[
            P_1(x) = P_0(S_1 = x) = \begin{cases}
                \frac{1}{2} & \tif x \in \set{-1, 1} \\
                0 & \otherwise.
            \end{cases}
        \]
        Thus,
        \[
            \Fourrier(P_1)(x) = \frac{1}{2}\parenthesis{e^{ix} + e^{-ix}} = \cos(x).
        \]
        And $ \Fourrier(P_n) = \bigparenthesis{\Fourrier(P_1)}^n = (\cos x)^n$.

        Finally, 
        \[
            \Fourrier\parenthesis{\sum P_n} = \sum_n \Fourrier(P_n) = 
            \sum_n (\cos x)^n = \frac{1}{1 - \cos x}.
        \]
        Applying the inverse Fourrier transform,
        \[
            \sum_{n = 0}^\infty P_n(0) = \frac{1}{2\pi} \int_{-\pi}^{\pi}
            \frac{1}{1 - \cos x} e^{i \cdot 0 \cdot x} dx = \infty
        \]

        In more dimensions, the Fourrier transform applies similarly,
        \[
            \func{\Fourrier f}{\R}{\C}
            {\Fourrier f(x)} {
                \sum_{k \in \Z^d} f(k) e^{ik \cdot x}
            }
        \]
        where $k \cdot x$ is the scalar product and which satisfies \begin{itemize}
            \item $\Fourrier(f * g)(x) = \Fourrier(f)(x) \Fourrier(g)(x)$.
            \item \[
                f(k) = \parenthesis{\frac{1}{2\pi}}^d
                 \iiint_{[-\pi, \pi]^d} \Fourrier f(x) e^{-ik \cdot x} \, dx
            \]
        \end{itemize}

        From which we obtain by the same process 
        \begin{align*}
            \sum_n P_n(0) &= 
                \parenthesis{\frac{1}{2\pi}}^d
                \int_{[-\pi, \pi]^d} 
                \frac{1}{1 - \frac{1}{d} \sum_{i = 1}^d \cos(x_i)} dx
            \\&= 
                \int_{[-\pi, \pi]^d} 
                \frac{1}{\norm{x}^2} dx.
        \end{align*}

        Which when $d = 1, 2$ diverges, and converges for the case $d = 3$, 
        by a transformation to polar coordinates.
    \end{proof}

    So if $d$ is 1 or 2, $\P{\exists n, S_n = 0} = 1$.

    \begin{corollary}
        If $d = 1, 2$, for any $x \in \Z^d$, 
        $\P{\exists n, S_n = x} = 1$.
    \end{corollary}

    \begin{proposition}
        Let $d = 1$ and $T_0$ be the random variable indicating the first time $t$ such that 
        $S_t = 0$. 
        \[
            \E{T_0} = \infty.
        \]
    \end{proposition}

    \begin{proof}
        \begin{itemize}
            \item $\E{T_0} = \sum_{k \geq 0} \P{T_0 > k}$
            \item $\P(T_0 > k) = 1 - \P{T_0 \leq k}$
            \item We need to study $P_0(T_0 \leq k)$.
                For that we separate according to $S_k > 0$ or $S_k \leq 0$,
                study it conbinatorially, and use the reflexion priinciple.
        \end{itemize}
    \end{proof}

    Let $T_{0, N}$ be the first time such that $S_{T_{0, N}} \in \set{0, N}$. 
    Let $A = \set{0, \dots, N}$.

    \begin{proposition}
        For any $x \in \set{0, \dots, N}$,
        \[
            \IE_x[T_{0,N}] = x(N - x)
        \]
    \end{proposition}

    \begin{corollary}
        \[
            \IE_0[T_0] = \infty
        \]
    \end{corollary}

    \begin{proof}
        (of proposition)
        Relations on $\IE_0[T_{0, N}]$:
        \begin{itemize}
            \item Boundary condition: $\IE_0[T_{0, N}] = \IE_n[T_{0, N}] = 0$. 
            \item Bulk condition: $\IE_x[T_{0, N}] = 1 + 
                \frac{1}{2} \IE_{x-1}[T_{0, N}]
                + \frac{1}{2} \IE_{x+1}[T_{0, N}]$.
        \end{itemize}

        With $f: A \to \R$, we define $\Delta f(x) = \frac{1}{2} \parenthesis{
            f(x - 1) + f(x + 1)
        } - f(x)$. 
        
        Here $\Delta \IE_x[T_{0, N}] = -1$. So 
        $\IE_x[T_{0, N}]$ satisfies the following DPDE:
        \[
            (*) \begin{cases}
                f(0) = f(N) = 0 \\
                f\Delta f(x) = -1
            \end{cases}
        \]

        We first check that $x \mapsto x(N - x)$ is a solution of $(*)$,
        then prove unicity of the solution.
    \end{proof}

    \begin{proposition}
        \[
            \IP[S_{T_{0, N}} = 0] = \frac{n - x}{n}
        \]
    \end{proposition}

    \begin{proof}
        We have the following conditions:
        \begin{itemize}
            \item $f(0) = 1$
            \item $f(N) = 0$
            \item $\IP_x[S_{T_{0, N}} = 0] = 
                \frac{1}{2} \IP_{x-1} (S_{T_{0, N}})
                + \frac{1}{2} \IP_{x+1} (S_{T_{0, N}})
            $ so \[
                \Delta f(x) = 0
            \]
        \end{itemize}

        Then we check that $\frac{n-x}{x}$ satisfies the system, and that the
        solution is unique.
    \end{proof}

    \paragraph{The general setting for the DPE.}
    Let $G \subset \Z^d$ be the induced graph. 
    $\d G$ is the set of points $(x, y) \in G$ adjacent to
    points of $G$ not in $G$.
    We consider $F: \d G \to \R$ and we define the laplacian
    with $F$ boundary.
    \[
        \func{\Delta^F}{\R^G}{\R^G}
            {f}{\Delta f(x) 
                = \frac{1}{2d} \sum_{x \sim y} f(y) - f(x)}
    \]
    with the convention $f(y) = F(y)$ if $y \d G$.

    \begin{proposition}
        $\Delta^F$ is bijective.
    \end{proposition}

    \begin{theorem}
        For any $F$ on $\d G$ and for all $\rho$ on $G$, 
        there exists one and only one solution to 
        \[ 
            \begin{cases}
                f(x) = F(x) & \text{on } \d G \\
                \Delta f(x) = \rho(x) & \text{on } G \\
            \end{cases}
        \]
    \end{theorem}

    Since the problem is linear, we can solve it by studing only
    \[
        (1)~\begin{cases}
            \Delta f = 0 & \text{on } G \\
            f = F        & \text{on } \d G
        \end{cases}
        \andquad
        (2) \begin{cases}
            \Delta f = \rho & \text{on } G \\
            f = 0           & \text{on } \d G
        \end{cases}
    \]
    Which can also be simplified to 
    \[
        \begin{cases}
            \Delta f = 0 & \text{on } G \\
            f = \delta_y & \text{on } \d G, y \in \d G
        \end{cases}
        \andquad
        \begin{cases}
            \Delta f = -\delta_y & \text{on } G, y \in G \\
            f = 0           & \text{on } \d G
        \end{cases}
    \]

    The solution to the first problem is $H_G(x, y)$, 
    the \emph{Harmonic Measure}.
    The solution to the second problem is $G(x, y)$,
    the \emph{Green function}.

    The solution to $(1)$ is thus \[
        \sum_{y \in \d G} f(y)H_G(x, y)
    \],
    and the solution to $(2)$ is \[
        \sum_{y \in G} -\rho(x)G(x, y)
    \].

    \paragraph{A probabilistic interpretation of $H_G, G$.}
    For $(1)$, the discret Dirichlet problem,
    \[
        H_G(x, y) = \IP_x(S_{T_{\d g}} = y)
    \]
    So the global solution is $\IE_x[F(S_{T_{\d g}})]$.

    For $(2)$, it is $G(x, y) = \E{\text{Number of visits at } y < T_{\d G}}$.
    Which translates too \[
        \IE_x \left[ 
            \sum_{n = 0}^{T_{\d G} - 1} 
                -\rho(S_n)
        \right]
    \]

    So the global solution is \[
        \IE_x\left[ 
            \sum_{n = 0}^{T_{\d G} - 1} 
                -\rho(S_n)
            + F(S_{T_{\d G}})
         \right]
    \]

    \subsection{Discrete Heat equation}

    Let I$f(n, x)$, $n \in \N$, $x \in \IG \cup \d \IG$.
    Let $\d_n f(n, x) = f(n + 1, x) - f(n, x)$.

    \begin{definition}
        \[
            \begin{cases}
                \d_n f = \Delta f \\
                f(0, x) = F & \forall x \in \IG \\
                f(n, x) = G & \forall n, \forall x \in \d \IG
            \end{cases}
        \]
    \end{definition}

    Let \[
        f(n, x) = \begin{cases}
            \IP_x(S_{n \wedge T_{\d G}} = y) & \tif y \in \IG \\
            0 & \otherwise.
        \end{cases}
    \]

    It turns out that $f$ is a solution to the discrete heat equation:
    \[
        \begin{cases}
            \d_n f = \Delta f \\
            f(0, y) = 0 & \forall y \in \IG \\
            f(n, y) = \delta_{x = y} & \forall n, \forall y \in \d \IG
        \end{cases}
    \]

    In 1D, we have $f(n + 1, y) = \frac{1}{2}(f(n, x-1) + f(n, x+1))$,
    so $f(n+1, -) = Qf(n, -)$, where \[
        Q = \begin{pmatrix*}
            0 & 1/2 & 0 & \dots & 0 \\
            1/2 & 0 & 1/2  && \vdots\\
            0 & 1/2 & \ddots && 0 \\
            \vdots &&& 0 & 1/2 \\
            0 & \dots & & 1/2 & 0 \\
        \end{pmatrix*}    
    \]
    


    \newpage
    .

    \[  
        \norm{A} = \sup \set{\abs{
            \langle Ax, x \rangle
        } :
            x \in X, \norm{x} \leq 1
        }
    \]
\end{document}
